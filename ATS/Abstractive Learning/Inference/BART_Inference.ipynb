{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cde629-5e05-4130-b7be-9770222f198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BartConfig, BartTokenizer, BartForConditionalGeneration, AdamW, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c120424-5eb2-43f8-a92d-3afe0ce8d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file for which we need the predictions.\n",
    "df = pd.read_excel('../DATA/BART_Test_Merged_corrupted.xlsx')\n",
    "#df = pd.read_excel('../Test_2_Records (2).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af226f6c-3cee-4bb7-8f1b-9b88e06171b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>distilbart-cnn-12-6</th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>noisy</th>\n",
       "      <th>Pronoun_replaced</th>\n",
       "      <th>deleted_added_noise</th>\n",
       "      <th>CBART_noisy</th>\n",
       "      <th>CBART_Pronoun_replaces</th>\n",
       "      <th>CBART_deleted_added_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "      <td>U.S consumer advisory group set up by the Dep...</td>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>experts did not question if  packed out planes...</td>\n",
       "      <td>experts question if packed out planes are putt...</td>\n",
       "      <td>if packed out planes planes are putting passen...</td>\n",
       "      <td>u.s consumer advisory group set up by united ...</td>\n",
       "      <td>u.s consumer advisory group set up by a depart...</td>\n",
       "      <td>u.s consumer advisory advisory group group set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "      <td>Rahul Kumar, 17, climbed into the enclosure a...</td>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>drunk teenage boy did not climb into lion encl...</td>\n",
       "      <td>drunk teenage boy climbed into lion enclosure ...</td>\n",
       "      <td>drunk climbed lion enclosure at in west . kuma...</td>\n",
       "      <td>rahul kumar, 17, did not climb into the enclo...</td>\n",
       "      <td>rahul kumar, 17, climbed into a enclosure at a...</td>\n",
       "      <td>rahul kumar, 17, into the at kamla nehru zoolo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  \\\n",
       "0  Experts question if  packed out planes are put...   \n",
       "1  Drunk teenage boy climbed into lion enclosure ...   \n",
       "\n",
       "                                 distilbart-cnn-12-6  \\\n",
       "0   U.S consumer advisory group set up by the Dep...   \n",
       "1   Rahul Kumar, 17, climbed into the enclosure a...   \n",
       "\n",
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "\n",
       "                                               noisy  \\\n",
       "0  experts did not question if  packed out planes...   \n",
       "1  drunk teenage boy did not climb into lion encl...   \n",
       "\n",
       "                                    Pronoun_replaced  \\\n",
       "0  experts question if packed out planes are putt...   \n",
       "1  drunk teenage boy climbed into lion enclosure ...   \n",
       "\n",
       "                                 deleted_added_noise  \\\n",
       "0  if packed out planes planes are putting passen...   \n",
       "1  drunk climbed lion enclosure at in west . kuma...   \n",
       "\n",
       "                                         CBART_noisy  \\\n",
       "0   u.s consumer advisory group set up by united ...   \n",
       "1   rahul kumar, 17, did not climb into the enclo...   \n",
       "\n",
       "                              CBART_Pronoun_replaces  \\\n",
       "0  u.s consumer advisory group set up by a depart...   \n",
       "1  rahul kumar, 17, climbed into a enclosure at a...   \n",
       "\n",
       "                           CBART_deleted_added_noise  \n",
       "0  u.s consumer advisory advisory group group set...  \n",
       "1  rahul kumar, 17, into the at kamla nehru zoolo...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc987ca-4e47-4ecc-8f18-deb6ff6778cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   highlights                 503 non-null    object\n",
      " 1   distilbart-cnn-12-6        503 non-null    object\n",
      " 2   id                         503 non-null    object\n",
      " 3   article                    503 non-null    object\n",
      " 4   noisy                      503 non-null    object\n",
      " 5   Pronoun_replaced           503 non-null    object\n",
      " 6   deleted_added_noise        503 non-null    object\n",
      " 7   CBART_noisy                503 non-null    object\n",
      " 8   CBART_Pronoun_replaces     503 non-null    object\n",
      " 9   CBART_deleted_added_noise  503 non-null    object\n",
      "dtypes: object(10)\n",
      "memory usage: 39.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538be142-0e4f-4cea-8abc-cf0fad334f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding everything.\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 2021\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220caa4c-414c-4bea-a538-81ee87808860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer and finetuned model.\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"../Training/BART_Model_article_BART/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d69cd28-d442-4476-9eec-f1f3de551d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving the model to GPU.\n",
    "_ = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ee14dc-c5fd-4af4-84a1-8016c742b9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>distilBART</th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Ramsey says he has no problem shaking ha...</td>\n",
       "      <td>Queens Park Rangers host Chelsea in Premier Le...</td>\n",
       "      <td>519e5c0f26ad35706573a1b18db79520ae00ad3e</td>\n",
       "      <td>Queens Park Rangers manager Chris Ramsey has r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB4 put British cars back on map going 140mph ...</td>\n",
       "      <td>Actor Peter Ustinov bought the Aston Martin DB...</td>\n",
       "      <td>132f2db92fcfb69b0f3b28dbc6324a103e3994b8</td>\n",
       "      <td>A classic Aston Martin once owned by Spartacus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  \\\n",
       "0  Chris Ramsey says he has no problem shaking ha...   \n",
       "1  DB4 put British cars back on map going 140mph ...   \n",
       "\n",
       "                                          distilBART  \\\n",
       "0  Queens Park Rangers host Chelsea in Premier Le...   \n",
       "1  Actor Peter Ustinov bought the Aston Martin DB...   \n",
       "\n",
       "                                         id  \\\n",
       "0  519e5c0f26ad35706573a1b18db79520ae00ad3e   \n",
       "1  132f2db92fcfb69b0f3b28dbc6324a103e3994b8   \n",
       "\n",
       "                                             article  \n",
       "0  Queens Park Rangers manager Chris Ramsey has r...  \n",
       "1  A classic Aston Martin once owned by Spartacus...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c907c7bf-19a9-4eb2-b812-9df723feec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   highlights  2 non-null      object\n",
      " 1   distilBART  2 non-null      object\n",
      " 2   id          2 non-null      object\n",
      " 3   article     2 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9dac6c-af06-4550-b9bf-9e0979123ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the prompt at nth loaction in a predefined format for summarization.\n",
    "def prompt(n):\n",
    "    #print(df.iloc[n]['highlights'])\n",
    "    return 'summarize: %s' % (df.iloc[n]['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ddf687-44ab-46e5-9891-88b8753c75f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list for saving the Predictions from model.\n",
    "Pred = []\n",
    "\n",
    "# assigning Batch size for inference.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# looping thought all the examples in the dataset.\n",
    "for i in trange(0, len(df), BATCH_SIZE):\n",
    "    \n",
    "    # try and catch block \n",
    "    # because the last batch if the data is not present for batch size the we will get error.\n",
    "    try:\n",
    "        # getting all prompts with batch size as list.\n",
    "        TEXT = [prompt(j) for j in range(i, i+BATCH_SIZE)]\n",
    "    except:\n",
    "        TEXT = [prompt(j) for j in range(i, len(df))]\n",
    "    \n",
    "    # tokenising the text using tokenizer. And moving to GPU.\n",
    "    inputs = tokenizer(TEXT, max_length=300, padding=\"max_length\", truncation=True, return_tensors='pt').to('cuda:0')\n",
    "    \n",
    "    # generating the summary using generate method in model.\n",
    "    output = model.generate(**inputs, max_length=300)\n",
    "    \n",
    "    # converting back the generated token to text for all summaries in a batch.\n",
    "    Pred.extend(tokenizer.batch_decode(output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f21b1cf-4888-47f0-9939-1ba0c084e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns namde  predictions and assigning pred list\n",
    "df['Predictions'] = Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c13fefe-c71d-4538-9381-4eb5e10e9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to an excel or csv.\n",
    "df.to_excel(\"../Test_2_records_Predicted.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc98d7-e3d8-43db-bd75-1df3a6e68416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BottleSum",
   "language": "python",
   "name": "bottlesum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
